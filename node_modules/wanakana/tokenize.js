'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _isEmpty = require('./utils/isEmpty');

var _isEmpty2 = _interopRequireDefault(_isEmpty);

var _isCharJapanesePunctuation = require('./utils/isCharJapanesePunctuation');

var _isCharJapanesePunctuation2 = _interopRequireDefault(_isCharJapanesePunctuation);

var _isCharKanji = require('./utils/isCharKanji');

var _isCharKanji2 = _interopRequireDefault(_isCharKanji);

var _isCharHiragana = require('./utils/isCharHiragana');

var _isCharHiragana2 = _interopRequireDefault(_isCharHiragana);

var _isCharKatakana = require('./utils/isCharKatakana');

var _isCharKatakana2 = _interopRequireDefault(_isCharKatakana);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }

// TODO: worth splitting into utils? so far not used anywhere else
function getType(input) {
  switch (true) {
    case (0, _isCharJapanesePunctuation2.default)(input):
      return 'japanesePunctuation';
    case (0, _isCharKanji2.default)(input):
      return 'kanji';
    case (0, _isCharHiragana2.default)(input):
      return 'hiragana';
    case (0, _isCharKatakana2.default)(input):
      return 'katakana';
    default:
      return 'romaji';
  }
}

/**
 * Splits input into array of [Kanji](https://en.wikipedia.org/wiki/Kanji), [Hiragana](https://en.wikipedia.org/wiki/Hiragana), [Katakana](https://en.wikipedia.org/wiki/Katakana), and [Romaji](https://en.wikipedia.org/wiki/Romaji) tokens.
 * Does not split into parts of speech!
 * @param  {String} input text
 * @return {Array} text split into tokens
 * @example
 * tokenize('ふふフフ')
 * // => ['ふふ', 'フフ']
 * tokenize('感じ')
 * // => ['感', 'じ']
 * tokenize('私は悲しい')
 * // => ['私', 'は', '悲', 'しい']
 * tokenize('what the...私は「悲しい」。')
 * // => ['what the...', '私', 'は', '「', '悲', 'しい', '」。']
 */
function tokenize() {
  var input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';

  if ((0, _isEmpty2.default)(input)) return [''];
  var chars = [].concat(_toConsumableArray(input));
  var head = chars.shift();
  var prevType = getType(head);

  var result = chars.reduce(function (tokens, char) {
    var currType = getType(char);
    var sameType = currType === prevType;
    prevType = getType(char);
    if (sameType) {
      var prev = tokens.pop();
      return tokens.concat(prev.concat(char));
    }
    return tokens.concat(char);
  }, [head]);

  return result;
}

exports.default = tokenize;